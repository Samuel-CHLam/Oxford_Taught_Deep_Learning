{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel-CHLam/Oxford_Taught_Deep_Learning/blob/main/Theory_of_Deep_Learning_MT2022_PS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Ea0Ks-g87k"
      },
      "source": [
        "# 1. Training Networks\n",
        "In this section we will build two Neural Networks, one from scratch, and one based on the high-level functions provided by Tensorflow.\n",
        "\n",
        "We will build a net from scratch to solve the XOR problem, and to do this we will rely on the backpropagation formulae that you will derive. We will also build a network with Tensorflow to introduce you to their API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxuEwxsQAbr"
      },
      "source": [
        "**Part (a)**: Consider a standard feedforward network defined by $h_1 = x$ and $h_{j+1} = \\sigma(W^{(j)} h_j + b^{(j)})$ for $j = 1,..., N − 1$, and define the loss as the sum of squared errors, $L(b,W) = \\sum_{i=1}^n \\|h_N(x_i) − y_i\\|^2$. Derive the formulae used for ‘backpropagation’, which would be used to update the weights and biases in the network when optimising the loss function using gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpHsHh8VQCQ9"
      },
      "source": [
        "*Solution.* We first derive the backpropagation for the $j=N-1$ weights and bias. For simplicity, we define $z^{(j)} = W^{(j)} h_j + b^{(j)}$, and we adopt the notation of $[z]_k$ being the $k$-th entry of the vector $z$. \n",
        "\n",
        "We note that $L(b,W) = \\sum_{i=1}^n L_i(b,W)$ where $L_i(b,W) = \\|h_N(x_i) - y_i \\|^2$. We will derive the derivatives for $L_i$ -- the derivatives for $L$ is the sum of derivatives for $L_i$. We finally note that \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "L_i(b,W) &= \\sum_{k} [h_N(x_i) - y_i]^2_k \\\\\n",
        "&= \\sum_{k} [\\sigma(z^{(N-1)}) - y_i]^2_k \\\\\n",
        "&= \\sum_{k} \\left(\\left[\\sigma(W^{(N-1)} h_{N-1} + b^{(N-1)})\\right]_k - [y_i]_k \\right)^2 \\\\\n",
        "&= \\sum_{k} \\left(\\sigma \\left( [W^{(N-1)} h_{N-1}]_k + b^{(N-1)}_k \\right) - [y_i]_k \\right)^2 \\\\\n",
        "&= \\sum_{k} \\left(\\sigma \\left( \\sum_{\\ell} W^{(N-1)}_{k,\\ell} h^{(N-1)}_\\ell + b^{(N-1)}_k \\right) - [y_i]_k \\right)^2\n",
        "\\end{aligned}$$\n",
        "\n",
        "We then have\n",
        "$$\n",
        "\\frac{\\partial L_i}{\\partial z^{(N-1)}_k} = 2\\left(\\sigma \\left( z^{(N-1)}_k \\right) - [y_i]_k \\right) \\sigma'(z^{(N-1)}_k),\n",
        "$$\n",
        "and \n",
        "$$\n",
        "\\frac{\\partial L_i}{\\partial b^{(N-1)}_k} = \\frac{\\partial L}{\\partial z^{(N-1)}_k} = 2\\left(\\sigma \\left( z^{(N-1)}_k \\right) - [y_i]_k \\right) \\sigma'(z^{(N-1)}_k).\n",
        "$$\n",
        "\n",
        "Moreover, we have\n",
        "$$\\frac{\\partial L_i}{\\partial W^{(N-1)}_{k,\\ell}} = 2\\left(\\sigma \\left( z^{(N-1)}_k \\right) - [y_i]_k \\right) \\sigma'(z^{(N-1)}_k) h_\\ell^{(N-1)}$$\n",
        "\n",
        "As a result, we have the following total derivatives:\n",
        "$$\\nabla_{b^{(N-1)}} L_i = 2(h_N(x_i) - y_i) \\odot \\sigma'(z^{(N-1)})$$\n",
        "and \n",
        "$$\\nabla_{W^{(N-1)}} L_i= 2\\left[(h_N(x_i) - y_i) \\odot \\sigma'(z^{(N-1)}) \\right] \\left(h_{N-1} \\right)^\\top$$\n",
        "\n",
        "Let us also record the following result:\n",
        "$$\\frac{\\partial L_i}{\\partial [h_{N-1}]_\\ell} = 2\\left(\\sigma \\left( z^{(N-1)}_k \\right) - [y_i]_k \\right) \\sigma'(z^{(N-1)}_k) W_{k,\\ell}$$\n",
        "\n",
        "Since $W_{k,\\ell} = W^\\top_{\\ell,k}$, we have\n",
        "$$\\nabla_{h^{(N-1)}} L_i = 2(W^{(N-1)})^\\top \\left[(h_N(x_i) - y_i) \\odot \\sigma'(z^{(N-1)}) \\right]$$\n",
        "\n",
        "We may follow similar method to derive the recursive formula for \"backpropagation\". In fact, we have, for $j \\leq N-1$,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\nabla_{b^{(j-1)}} L_i &= \\nabla_{h^{(j)}} L_i \\odot \\sigma'(z^{(j-1)}) \\\\\n",
        "\\nabla_{W^{(j-1)}} L_i &= \\nabla_{h^{(j)}} L_i \\odot \\sigma'(z^{(j-1)}) \\left(h_{j-1} \\right)^\\top \\\\\n",
        "\\nabla_{h^{(j-1)}} L_i &= \\left(W^{(j-1)} \\right)^\\top \\nabla_{h^{(j)}} L_i\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfXqkaZiLMM"
      },
      "source": [
        "**Part (b) XOR problem - NN from Scratch**\n",
        "\n",
        "In this problem we have four possible inputs with two possible outcomes; \n",
        "\n",
        " \n",
        "> $x_1 = 0, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=0$\n",
        "\n",
        "> $x_1 = 0, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=1$\n",
        "\n",
        "> $x_1 = 1, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=1$\n",
        "\n",
        "> $x_1 = 1, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=0$\n",
        "\n",
        "In the problem sheet you may have noticed that a two layer NN  could solve this problem exactly. Here we will see that on a 2-layer net with Sigmoid activation functions, with a random intialisation and the mean square loss, back-prop is able to converge to a pseudo-optimal solution. We will then consider a visualisation of how the neural network divides the input space as a classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz4eQDGFI7b0"
      },
      "source": [
        "**Exercise** The class for the NeuralNet is already defined except for the backpropagation function, which you have to complete.\n",
        "\n",
        "Note: Once you have implemented backprop, if you get poor performance, try running the cell again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBiFs8xZGNlM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "    \n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1.0 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        dimension = 2\n",
        "        self.input        = x\n",
        "        self.weights1     = np.random.rand(dimension, x.shape[1])      #np.array([[-1,1],[1,-1]], dtype=np.float)\n",
        "        self.weights2     = np.random.rand(1,dimension)      \n",
        "        self.bias1        = np.random.rand(dimension,1)      #0.5*np.ones((dimension,1))\n",
        "        self.bias2        = np.random.rand(1,1)           \n",
        "        self.y            = y\n",
        "        self.output       = np.zeros(self.y.shape)\n",
        "        self.activation   = sigmoid\n",
        "        self.d_activation = sigmoid_derivative\n",
        "\n",
        "    def feedforward(self,x):\n",
        "        self.x = np.expand_dims(x,axis =1)\n",
        "        self.layer1 = self.activation(self.weights1 @  self.x + self.bias1)\n",
        "        self.output = self.activation(self.weights2 @ self.layer1 + self.bias2)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = np.expand_dims(x,axis =1)\n",
        "        layer1 = self.activation(self.weights1 @  x + self.bias1)\n",
        "        output = self.activation(self.weights2 @ layer1 + self.bias2)\n",
        "        return output\n",
        "\n",
        "    def backprop(self):\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        d_weights1 = np.zeros(self.weights1.shape)\n",
        "        d_weights2 = np.zeros(self.weights2.shape)\n",
        "        d_bias1    = np.zeros(self.bias1.shape)\n",
        "        d_bias2    = np.zeros(self.bias2.shape)\n",
        "        \n",
        "        for j in range(4):\n",
        "          # compute gradient per each input image\n",
        "          single_input = self.input[j]\n",
        "          self.feedforward(single_input)\n",
        "\n",
        "          d_bias2    += 2 * (self.output - self.y[j][0]) * sigmoid_derivative(self.output) \n",
        "          d_weights2 += 2 * ((self.output - self.y[j][0]) * sigmoid_derivative(self.output)) @ self.layer1.T\n",
        "          d_h1       =  2 * self.weights2.T @ ((self.output - self.y[j][0]) * sigmoid_derivative(self.output))\n",
        "          d_bias1    += d_h1 * sigmoid_derivative(self.layer1)\n",
        "          d_weights1 += (d_h1 * sigmoid_derivative(self.layer1)) @ single_input.reshape(-1,1).T\n",
        "\n",
        "        self.weights1 -= d_weights1\n",
        "        self.weights2 -= d_weights2\n",
        "        self.bias1    -= d_bias1\n",
        "        self.bias2    -= d_bias2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcIi0lOGp4gd"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "nn = NeuralNetwork(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMHAELDqA4b",
        "outputId": "4a9b68c8-ce68-48f3-a029-53b88aaa37a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.feedforward(nn.input[0])\n",
        "nn.y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39eIVqN6p7I8",
        "outputId": "bc5fe2ca-db54-46a3-a1ce-223dcff7965f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:\n",
            " [[0]\n",
            " [0]]  ---> [[0.00899394]]\n",
            "Prediction:\n",
            " [[0]\n",
            " [1]]  ---> [[0.99236799]]\n",
            "Prediction:\n",
            " [[1]\n",
            " [0]]  ---> [[0.99236814]]\n",
            "Prediction:\n",
            " [[1]\n",
            " [1]]  ---> [[0.00781651]]\n"
          ]
        }
      ],
      "source": [
        "for i in range(10000):\n",
        "    nn.backprop()\n",
        "for j in range(4):\n",
        "    nn.feedforward(X[j])\n",
        "    print('Prediction:\\n', nn.x, ' --->' , nn.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncvIv2vepg6"
      },
      "source": [
        "Now we will plot how the domain has been split. In the left figure we will see the outputs of the NN, while on the right we visualise the classification of these outputs i.e. any value above 0.5 identifies class 1, 0 otherwise, which shows us the decision boundary of the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "jI1Tv1mAeyl9",
        "outputId": "754e7196-ffc6-46c1-8072-fdb75418bf20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f6e1a10bd90>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mu = np.linspace(0,1,100)\n",
        "gamma = np.linspace(0,1,100)\n",
        "\n",
        "# filling the heatmap, value by value\n",
        "fun_map = np.empty((mu.size, gamma.size))\n",
        "for i in range(mu.size):\n",
        "    for j in range(gamma.size):\n",
        "        net_val = nn.call([mu[i], gamma[j]])\n",
        "        if net_val>0.5:\n",
        "          fun_map[i,j] = 1\n",
        "        else:\n",
        "          fun_map[i,j] = 0\n",
        "\n",
        "fun_map_2 = np.empty((mu.size, gamma.size))\n",
        "for i in range(mu.size):\n",
        "    for j in range(gamma.size):\n",
        "        fun_map_2[i,j] = nn.call([mu[i], gamma[j]])\n",
        "\n",
        "fig = plt.figure()\n",
        "s = fig.add_subplot(1, 2, 1, xlabel='$x$', ylabel='$y$')\n",
        "im = s.imshow(\n",
        "    fun_map_2,\n",
        "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
        "    origin='lower')\n",
        "fig.colorbar(im)\n",
        "s = fig.add_subplot(1, 2, 2, xlabel='$x$', ylabel='$y$')\n",
        "im = s.imshow(\n",
        "    fun_map,\n",
        "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
        "    origin='lower')\n",
        "fig.colorbar(im)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzDVeZloHFwy"
      },
      "source": [
        "N.B. The transition fase with the sigmoid activation function is sharp, and so the NN more-or-less splits the domain into piecwise constant regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIrwTlPU7iVe"
      },
      "source": [
        "**Part (c): Training MNIST.** First, we have to upload the dataset; keras, an interface for tensorflow, allows us to do this with a one line command. We then can use the Sequence model class from TF to add different layers to our network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJpPyFJyDXC9",
        "outputId": "40cfee70-c624-4b1f-ba8c-881ca9757c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels)= mnist.load_data()\n",
        "\n",
        "print(train_images.shape) # Check if images are loaded correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9c213Z3MfrD"
      },
      "source": [
        "**Exercise** You now have to generate a two layer network with hidden dimension of 128 via the sequential command in Tensorflow. This should allow you to achieve 92% accuracy with only 15 epochs of training!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO2O_0T7MiHb",
        "outputId": "a4b0b198-06f2-4f62-f260-d0991e21a4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import Input\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Generate data\n",
        "x_train = train_images\n",
        "y_train = train_labels\n",
        "\n",
        "x_test = test_images\n",
        "y_test = test_labels\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# build the architecture with Sequential\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\n",
        "model.add(Dense(10, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model, which involved shows a loss function, an optimiser, and the performance metrics you want to track\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVt3HV5hM_bJ",
        "outputId": "35b3eb33-c336-4cdd-e617-93af61f06dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3461 - accuracy: 0.9080\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3006 - accuracy: 0.9188\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2807 - accuracy: 0.9207\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2597 - accuracy: 0.9271\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2444 - accuracy: 0.9312\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2390 - accuracy: 0.9324\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2295 - accuracy: 0.9354\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2172 - accuracy: 0.9382\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2105 - accuracy: 0.9409\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2042 - accuracy: 0.9419\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1977 - accuracy: 0.9434\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1923 - accuracy: 0.9446\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1958 - accuracy: 0.9441\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1895 - accuracy: 0.9456\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1808 - accuracy: 0.9480\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad12d62590>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train the architecture\n",
        "model.fit(x_train, y_train, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdgtcleFNDI9",
        "outputId": "7af6b6f8-981a-459b-d256-ca2bb25acd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9228\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.2586139142513275, 0.9228000044822693]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test the performance\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Expressivity\n",
        "\n",
        "**Part (a):** In Yarotsky (2016) it is proven that $f(x) = x^2$ on $[0, 1]$ can be approximated with any error $\\varepsilon > 0$ by a ReLU network having the depth and the number of weights and computation units $O(\\log(1/\\varepsilon))$. The proof relies on the following statement:\n",
        "\n",
        "**Claim:** Let $f_m$ be the piece-wise linear interpolation of $f(x) = x^2$ with $2^m+1$ uniformly distributed breakpoints $k$ , $k = 0,...,2^m$. The function $f$ approximates $f$ with the error $\\epsilon = 2^{−2m−2}$ (in the $\\ell^\\infty$ norm).\n",
        "\n",
        "Prove this statement."
      ],
      "metadata": {
        "id": "Y9Hh1yKMms_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Solution.* We note the following general result: let $f(x) = x^2$ on $x \\in [a,b]$ and $g(x)$ be its linear interpolation between the points $(a,a^2)$ and $(b,b^2)$, where $0\\leq a<b \\leq 1$. Then we have \n",
        "$$\n",
        "  g(x) = \\frac{b^2-a^2}{b-a}(x-a) + a^2 \\geq f(x), \\quad \\forall x \\in [a,b]\n",
        "$$\n",
        "We would like to find the maximum of $h(x) = g(x) - f(x)$. We note that\n",
        "$$\n",
        "  h'(x) = \\frac{b^2-a^2}{b-a} - 2x, \\quad h(x^*) = 0 \\text{ when } x^* = \\frac{b^2-a^2}{2(b-a)}\n",
        "$$\n",
        "Here $x^*$ is a maximum over $[a,b]$, because $h''(x) = -2 < 0$. Now we have\n",
        "$$\n",
        "\\sup_{x \\in [a,b]} |h(x)| = h(x^*) = 2x^* (x^* - a) + a^2 - (x^*)^2 = (x^* - a)^2.\n",
        "$$\n",
        "With this general result, we can plug in $a = k/2^m$ and $b = (k+1)/2^m$ for any $k = 0,...,2^m-1$. This leads to $x^* = (2k+1)/2^{m+1}$, and hence we conclude that the $\\ell^\\infty$ norm of approximation is\n",
        "$$\n",
        "\\sup_{x\\in [0,1]}|f_m(x) - f(x)| = \\left(\\frac{2k+1}{2^{m+1}} - \\frac{k}{2^m} \\right)^2 = 2^{-2m-2}.\n",
        "$$"
      ],
      "metadata": {
        "id": "g0KeY1LYmsyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part (b):** Recall from lectures that the ‘sawtooth’ function can be created by iteratively composing the single-hidden-layer network $f(x) = \\sigma(2\\sigma(x) − 4\\sigma(x − 1/2))$, where $\\sigma(x) = x_+ = max(x, 0)$. Can the same be achieved with a network of the same width and depth if hard-tanh activations are used instead of ReLU? If so, write down the corresponding function."
      ],
      "metadata": {
        "id": "M9PGuEbtqxyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Solution.* Yes! Writing $\\sigma$ as the $\\mathsf{hardtanh}$ function, then the following function is a sawtooth\n",
        "$$f(x) = \\frac{1}{2}{\\sigma(4x-1) - \\sigma(4x-3)}.$$"
      ],
      "metadata": {
        "id": "yJBH3RUFrHom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part (c):** Consider $n$-ap problem (the $n$-alternating-point problem). Dataset consisting of a set of $n$ uniformly spaced points within $[0, 1 − 2^{−n}]$ with alternating labels, i.e., the pairs $(x_i, y_i)$ with $x_i = i2^{−n}$, and $y_i = 0$ when $i$ is even. How many layers does a width-2 ReLU network need in order to have the capacity to solve the $n$-ap problem? How wide would the layers need to be if there were only two layers?"
      ],
      "metadata": {
        "id": "koSfjJMXylCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Solution.* We need at least $2n$ layers for a width-2 ReLU network to solve the $n$-ap problem. We need $2^n$ layers for a 2-layer ReLU network to solve the $n$-ap problem."
      ],
      "metadata": {
        "id": "dLPkbnfG0KT-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbdIpyUpNxec"
      },
      "source": [
        "The **$n$-ap problem** was shown to have an optimal solution with a particular construction of neural network. Do we find these coefficients/weights when training a network with that structure from randomly initialised weights?\n",
        "\n",
        "## 2(d) Train NN on n-ap problem\n",
        "\n",
        "Build the net in the case with $n=2^K, K=3$ and check if it converges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxwKrnWmPzrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Generate data\n",
        "X = np.array([[0],\n",
        "                  [.125],\n",
        "                  [.25],\n",
        "                  [.375],\n",
        "                  [.5],\n",
        "                  [.625],\n",
        "                  [.75],\n",
        "                  [.875]])\n",
        "y = np.array([[0],[1],[0],[1],[0],[1],[0],[1]])\n",
        "x_train = X\n",
        "y_train = y\n",
        "\n",
        "# Build a model\n",
        "# ...\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# ...\n",
        "\n",
        "scores = model.evaluate(X, y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "ynew = model.predict_classes(x_train)\n",
        "for i in range(len(x_train)):\n",
        "\tprint(\"Y=%s, Predicted=%s\" % (y_train[i], ynew[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zVbcSsha9xQ"
      },
      "source": [
        "And now let's plot the modelled function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5V40mAne235"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model(nn,x,y):\n",
        "  xx = np.linspace(0,1,10000)\n",
        "  yy = nn.predict(xx)\n",
        "  fig = plt.figure()\n",
        "  plt.plot(xx,yy)\n",
        "  plt.plot(x,y, 'rx')\n",
        "  \n",
        "plot_model(model, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2k7mG-BaBPn"
      },
      "source": [
        "## 2(e) Perturbed Solution of the n-ap problem\n",
        "\n",
        "Why is this optimum so hard to find? Let's implement the optimal function directly and see how a small perturbation to the parameters changes the function it computes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8lV3gR-aFNd"
      },
      "outputs": [],
      "source": [
        "# Fill in the weights and bias vactors given the optimal function to be composed, given in question 1b\n",
        "\n",
        "w1 = \n",
        "w2 = \n",
        "b1 = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2elCP_RaHrg"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(x,0)\n",
        "\n",
        "class f():\n",
        "  def __init__(self, num_blocks, noise_stddev=0):\n",
        "    self.weights  = []\n",
        "    self.biases = []\n",
        "    for i in range(num_blocks):\n",
        "      w1_n = w1+ np.random.normal(scale = noise_stddev, size = w1.shape)\n",
        "      w2_n = w2+ np.random.normal(scale = noise_stddev, size = w2.shape)\n",
        "      b1_n = b1+ np.random.normal(scale = noise_stddev, size = b1.shape)\n",
        "      self.weights.append([w1_n,w2_n])\n",
        "      self.biases.append(b1_n)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    output = x\n",
        "    for i in range(len(self.weights)):\n",
        "      output = relu(self.weights[i][1] @ (relu(self.weights[i][0] @ output + self.biases[i])))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBfBGCy5aRI3"
      },
      "outputs": [],
      "source": [
        "x = np.expand_dims(np.linspace(0,1,10000), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PARdoS6CaT3C"
      },
      "outputs": [],
      "source": [
        "no_noise = f(6,0)\n",
        "noise = f(6,0.1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x[0,:], no_noise.forward(x).T, label = \"Without noise\")\n",
        "\n",
        "plt.plot(x[0,:], noise.forward(x).T, label = \"With noise\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRVwoXF8avNB"
      },
      "source": [
        "## 2(f) Interatction Between Depth and Width\n",
        "\n",
        "Learning a piecewise smooth function from sample values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbyNydJZazTE",
        "outputId": "397ab38e-f65c-46ed-efa4-a29f0cb95358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0822 - mse: 0.0822\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0384 - mse: 0.0384\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0063 - mse: 0.0063\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0025 - mse: 0.0025\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb5aacd890>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "train_samples=10000\n",
        "\n",
        "x_train=np.expand_dims(np.sort(np.random.uniform(0,1,train_samples)), 1)\n",
        "\n",
        "#generate samples of y=sin(x * pi) for x\\in[0,1) and y=x^2 for x\\in[1/2,1]\n",
        "def test_func(x):\n",
        "    return np.sin(x*np.pi)*(x<1/2) + x**2*(x>=1/2)\n",
        "\n",
        "y_train=test_func(x_train)\n",
        "\n",
        "#uncommenting the below shows the samples\n",
        "#plt.figure()\n",
        "#plt.plot(x_train,y_train)\n",
        "\n",
        "#we now train a network base on the samples (x_train,y_train) and evaluate it on x_test.\n",
        "\n",
        "#consider varying the network width and depth, \n",
        "#width and depth are controlled through the variables \"width\" and \"depths respectively\", \n",
        "\n",
        "width=10\n",
        "depth=10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(width, input_dim=1, activation='relu'))\n",
        "\n",
        "for i in range(depth-2):\n",
        "  model.add(Dense(width, activation='relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer = 'adam',  metrics=['mse'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32,verbose=1)\n",
        "\n",
        "# scores = model.evaluate(X, y)\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1-__gjJPa882",
        "outputId": "2a00bcdc-92c0-4097-9471-59406c065ebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbb5921b990>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_test=np.linspace(0,1,10000)\n",
        "y_test = test_func(x_test)\n",
        "\n",
        "x_test = np.expand_dims(x_test,  axis=1)\n",
        "y_test_estimate = model(x_test)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_test,y_test_estimate, label = \"fitted\")\n",
        "plt.plot(x_test, y_test, label = \"ground truth\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPP_7EuecVk-"
      },
      "source": [
        "Try and do something similar to the code above - but for a 2-d function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OME92y2ScVNp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CullH2cIcVFY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}